{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mayaamohamed/Material-Stream-Identification-System-assigment/blob/main/Ml_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5B3T9uLjoU71"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps\n",
        "import hashlib\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter, defaultdict "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def augment_image_cv(img, num_augments=1,\n",
        "                     rotation_range=15, shift_range=5,\n",
        "                     brightness_range=(0.8, 1.2), contrast_range=(0.8, 1.2),\n",
        "                     h_flip_prob=0.5, v_flip_prob=0.2,\n",
        "                     noise_std=0.02):\n",
        "    \"\"\"\n",
        "    img: numpy array of shape (H,W,3) or (H,W), values [0,1]\n",
        "    num_augments: number of augmented images to create\n",
        "    returns: list of augmented images\n",
        "    \"\"\"\n",
        "    augmented = []\n",
        "    img = img.astype(np.float32)\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    for _ in range(num_augments):\n",
        "        aug = img.copy()\n",
        "\n",
        "        # ----- Random rotation -----\n",
        "        angle = np.random.uniform(-rotation_range, rotation_range)\n",
        "        M_rot = cv2.getRotationMatrix2D((w/2, h/2), angle, 1)\n",
        "        aug = cv2.warpAffine(aug, M_rot, (w, h), borderMode=cv2.BORDER_REFLECT)\n",
        "\n",
        "        # ----- Random shift -----\n",
        "        tx = np.random.uniform(-shift_range, shift_range)\n",
        "        ty = np.random.uniform(-shift_range, shift_range)\n",
        "        M_shift = np.float32([[1, 0, tx], [0, 1, ty]])\n",
        "        aug = cv2.warpAffine(aug, M_shift, (w, h), borderMode=cv2.BORDER_REFLECT)\n",
        "\n",
        "        # ----- Random flips -----\n",
        "        if np.random.rand() < h_flip_prob:\n",
        "            aug = cv2.flip(aug, 1)\n",
        "        if np.random.rand() < v_flip_prob:\n",
        "            aug = cv2.flip(aug, 0)\n",
        "\n",
        "        # ----- Random brightness adjustment -----\n",
        "        factor_b = np.random.uniform(brightness_range[0], brightness_range[1])\n",
        "        aug = aug * factor_b\n",
        "\n",
        "        # ----- Random contrast adjustment -----\n",
        "        factor_c = np.random.uniform(contrast_range[0], contrast_range[1])\n",
        "        mean = np.mean(aug)\n",
        "        aug = np.clip((aug - mean) * factor_c + mean, 0, 1)\n",
        "\n",
        "        # ----- Add Gaussian noise -----\n",
        "        noise = np.random.normal(0, noise_std, aug.shape)\n",
        "        aug = np.clip(aug + noise, 0, 1)\n",
        "\n",
        "        # Ensure 3 channels for color images\n",
        "        if img.ndim == 3 and img.shape[2] == 3:\n",
        "            if aug.ndim == 2:\n",
        "                aug = cv2.cvtColor(aug, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "        augmented.append(aug)\n",
        "\n",
        "    return augmented\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1qSBzeK3py0m"
      },
      "outputs": [],
      "source": [
        "def load_dataset(root_folder, img_size=(128, 128), min_size=32, target_count=500):\n",
        "    \"\"\"\n",
        "    Load images from folders, apply preprocessing and data augmentation\n",
        "    to balance classes up to target_count images per class.\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    y = []\n",
        "    seen_hashes = set()\n",
        "\n",
        "    classes = [d for d in os.listdir(root_folder) if os.path.isdir(os.path.join(root_folder, d))]\n",
        "    print(\"Classes found:\", classes)\n",
        "\n",
        "    for class_name in classes:\n",
        "        class_path = os.path.join(root_folder, class_name)\n",
        "        images_in_class = []\n",
        "\n",
        "        for img_name in os.listdir(class_path):\n",
        "            img_path = os.path.join(class_path, img_name)\n",
        "\n",
        "            # Skip 0kb images\n",
        "            if os.path.getsize(img_path) == 0:\n",
        "                continue\n",
        "\n",
        "            # Repair EXIF transpose\n",
        "            try:\n",
        "                pil_img = Image.open(img_path)\n",
        "                pil_img = ImageOps.exif_transpose(pil_img)\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "            img = np.array(pil_img)\n",
        "\n",
        "            # Skip small images\n",
        "            if img.shape[0] < min_size or img.shape[1] < min_size:\n",
        "                continue\n",
        "\n",
        "            # Skip duplicates using hash\n",
        "            img_hash = hashlib.sha1(img.tobytes()).hexdigest()\n",
        "            if img_hash in seen_hashes:\n",
        "                continue\n",
        "            seen_hashes.add(img_hash)\n",
        "\n",
        "            # Resize\n",
        "            img = cv2.resize(img, img_size)\n",
        "\n",
        "            # Convert to grayscale\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Normalize\n",
        "            img = img / 255.0\n",
        "\n",
        "            images_in_class.append(img)\n",
        "\n",
        "        current_count = len(images_in_class)\n",
        "        print(f\"Class '{class_name}': {current_count} original images loaded\")\n",
        "\n",
        "        if current_count == 0:\n",
        "            print(f\"  WARNING: No images found for class '{class_name}'\")\n",
        "            continue\n",
        "\n",
        "        # Augmentation to reach target_count\n",
        "        num_needed = max(0, target_count - current_count)\n",
        "        augmented_images = []\n",
        "\n",
        "        for img in images_in_class:\n",
        "            num_aug_per_img = (num_needed // max(1, current_count)) + 1\n",
        "            augmented_images.extend(augment_image_cv(img, num_aug_per_img))\n",
        "\n",
        "        all_images = images_in_class + augmented_images[:num_needed]\n",
        "        print(f\"  {len(all_images) - current_count} images augmented for class '{class_name}'\")\n",
        "        print(f\"  Total images for class '{class_name}' after augmentation: {len(all_images)}\")\n",
        "\n",
        "        for img in all_images:\n",
        "            X.append(img.flatten())\n",
        "            y.append(class_name)\n",
        "\n",
        "    print(\"\\nFinal counts per class after full augmentation:\")\n",
        "    print(Counter(y))\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojtbLqTiwBEH",
        "outputId": "6c01e329-e7f5-4889-be58-dec25796ad95"
      },
      "outputs": [],
      "source": [
        "root_folder = \"/content/datasetml\"\n",
        "X, y = load_dataset(root_folder)\n",
        "print(np.unique(y))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def extract_hog(img_128x128):\n",
        "    \"\"\"\n",
        "    img_128x128: 2D grayscale image, either float in [0,1] or uint8 [0,255]\n",
        "    returns: 1D HOG feature vector\n",
        "    \"\"\"\n",
        "    img = img_128x128\n",
        "\n",
        "    # pipeline stores floats in [0,1], HOG in OpenCV expects uint8.\n",
        "    if img.dtype != np.uint8:\n",
        "        img = (np.clip(img, 0, 1) * 255).astype(np.uint8)\n",
        "\n",
        "    hog = cv2.HOGDescriptor(\n",
        "        _winSize=(128, 128),\n",
        "        _blockSize=(16, 16),\n",
        "        _blockStride=(8, 8),\n",
        "        _cellSize=(8, 8),\n",
        "        _nbins=9\n",
        "    )\n",
        "\n",
        "    feat = hog.compute(img)  # shape (N,1)\n",
        "    return feat.flatten()\n",
        "\n",
        "# Convert flattened X back into images\n",
        "X_imgs = X.reshape(-1, 128, 128)\n",
        "\n",
        "# Build feature matrix\n",
        "X_hog = np.vstack([extract_hog(im) for im in X_imgs]).astype(np.float32)\n",
        "\n",
        "print(\"Raw X shape:\", X.shape)\n",
        "print(\"HOG X_hog shape:\", X_hog.shape)\n",
        "print(\"Any NaNs in features?\", np.isnan(X_hog).any())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QcC1qq0qyWz-",
        "outputId": "f888a58c-5848-4e7d-9bfb-e70d95534777"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "class_indices = defaultdict(list)\n",
        "for idx, label in enumerate(y):\n",
        "    class_indices[label].append(idx)\n",
        "for class_name, indices in class_indices.items():\n",
        "    idx = random.choice(indices)\n",
        "    plt.imshow(X[idx].reshape(128,128), cmap='gray')\n",
        "    plt.title(class_name)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "idx = random.randint(0, len(X)-1)\n",
        "original_img = X[idx].reshape(128,128)\n",
        "\n",
        "plt.imshow(original_img, cmap='gray')\n",
        "plt.title(\"Original\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "augmented_imgs = augment_image_cv(original_img, num_augments=5)\n",
        "for i, aug_img in enumerate(augmented_imgs):\n",
        "    plt.imshow(aug_img, cmap='gray')\n",
        "    plt.title(f\"Augmented {i+1}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMzkS78hiGqX17MDfIRiiTs",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
